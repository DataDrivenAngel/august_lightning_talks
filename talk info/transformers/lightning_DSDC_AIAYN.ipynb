{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9f2dbcb",
   "metadata": {},
   "source": [
    "<img src=\"AIAYN_Draft_230426_85.png\" alt=\"Eq (1) of Attention is All You Need\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9facd2",
   "metadata": {},
   "source": [
    "The 2017 \"Attention is All You Need\" paper can be found here: https://arxiv.org/abs/1706.03762"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1252ec",
   "metadata": {},
   "source": [
    "The aim of this lightning talk is to start at that equation (1) and show it's equivalent to a Python dict lookup (with 1-hot encodings). Over a handful of 26 cells, we'll stepwise transform the familiar python dict lookup into the more mysterious equation (1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46eb629",
   "metadata": {},
   "source": [
    "**Recommended:** come to a talk on **Tuesday, September 20th, at George Mason University's Virginia Square campus (Van Metre Hall Auditorium - room 134)** for a more complete discussion of **Transformer architectures.**\n",
    "\n",
    "https://www.meetup.com/data-science-dc/events/295247462/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f7fac2",
   "metadata": {},
   "source": [
    "<img src=\"AIAYN_Draft_230426_86.png\" alt=\"A simple python dict\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51898e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1badc8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to show results in human readable form:\n",
    "def print_result(human_readable, result):\n",
    "    print(human_readable + \" = '\" + str(result) + \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148c41b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set query, q, to \"attitude\"\n",
    "q = \"attitude\"\n",
    "print_result(\"q\", q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54bf1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dict with keys and values (from 10 total tokens)\n",
    "KVdict = {\n",
    "             \"cat\" : \"jinx\",\n",
    "        \"medicine\" : \"meh\",\n",
    "           \"taste\" : \"bitter\",\n",
    "        \"attitude\" : \"yes\",\n",
    "     \"disposition\" : \"fickle\"}\n",
    "KVdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff8c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Python dict q, K, V result\n",
    "print_result(\"KVdict[q]\", KVdict[q])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961a1490",
   "metadata": {},
   "source": [
    "<img src=\"AIAYN_Draft_230426_87.png\" alt=\"1-hot vector mappings of keys and queries\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f9c107",
   "metadata": {},
   "source": [
    "*Why 1-hots? Rebecca Bilbro, Ph.D. has a minute on that: ->*  https://www.linkedin.com/posts/activity-7080150156112773120-VFD9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbec56ac",
   "metadata": {},
   "source": [
    "All K1map does is maps a token to its 1-hot, and all V1map does is map a 1-hot to its token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1474ac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dict of mappings of tokens to 1-hot vectors (tuples)\n",
    "Vec1hmap = {\n",
    "            \"cat\" : (1,0,0,0,0,0,0,0,0,0),\n",
    "       \"medicine\" : (0,1,0,0,0,0,0,0,0,0),\n",
    "          \"taste\" : (0,0,1,0,0,0,0,0,0,0),\n",
    "       \"attitude\" : (0,0,0,1,0,0,0,0,0,0),\n",
    "    \"disposition\" : (0,0,0,0,1,0,0,0,0,0),\n",
    "           \"jinx\" : (0,0,0,0,0,1,0,0,0,0),\n",
    "            \"meh\" : (0,0,0,0,0,0,1,0,0,0),\n",
    "         \"bitter\" : (0,0,0,0,0,0,0,1,0,0),\n",
    "            \"yes\" : (0,0,0,0,0,0,0,0,1,0),\n",
    "         \"fickle\" : (0,0,0,0,0,0,0,0,0,1)}\n",
    "Vec1hmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dae371",
   "metadata": {},
   "source": [
    "Vec1hmap just maps each key or value to its 1-hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6317f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dict of vector (immutable tuple for hashing) mappings of \n",
    "# 1-hots to tokens\n",
    "Vec2token = {\n",
    "    (1,0,0,0,0,0,0,0,0,0) : \"cat\",\n",
    "    (0,1,0,0,0,0,0,0,0,0) : \"medicine\",\n",
    "    (0,0,1,0,0,0,0,0,0,0) : \"taste\",\n",
    "    (0,0,0,1,0,0,0,0,0,0) : \"attitude\",\n",
    "    (0,0,0,0,1,0,0,0,0,0) : \"disposition\",\n",
    "    (0,0,0,0,0,1,0,0,0,0) : \"jinx\",\n",
    "    (0,0,0,0,0,0,1,0,0,0) : \"meh\",\n",
    "    (0,0,0,0,0,0,0,1,0,0) : \"bitter\",\n",
    "    (0,0,0,0,0,0,0,0,1,0) : \"yes\",\n",
    "    (0,0,0,0,0,0,0,0,0,1) : \"fickle\"}\n",
    "# Equivalently:\n",
    "# Vec2token = dict((v,k) for k,v in Vec1hmap.items())\n",
    "Vec2token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba10204",
   "metadata": {},
   "source": [
    "Vec2token just maps each 1-hot vector back to its token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac9fb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K1map is a mapping from each key to its 1-hot vector\n",
    "K1map = {        \"cat\" : Vec1hmap[\"cat\"],\n",
    "            \"medicine\" : Vec1hmap[\"medicine\"],\n",
    "               \"taste\" : Vec1hmap[\"taste\"],\n",
    "            \"attitude\" : Vec1hmap[\"attitude\"],\n",
    "         \"disposition\" : Vec1hmap[\"disposition\"],\n",
    "        }\n",
    "K1map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07736f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V1map is a mapping from each vector's 1-hot to its value\n",
    "V1map = {  Vec1hmap[\"jinx\"] : \"jinx\",\n",
    "            Vec1hmap[\"meh\"] : \"meh\",\n",
    "         Vec1hmap[\"bitter\"] : \"bitter\",\n",
    "            Vec1hmap[\"yes\"] : \"yes\",\n",
    "         Vec1hmap[\"fickle\"] : \"fickle\",\n",
    "        }\n",
    "V1map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7bb143",
   "metadata": {},
   "source": [
    "<img src=\"AIAYN_Draft_230426_88.png\" alt=\"1-hot vector mappings of keys and queries\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c5421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 1-hot vector, q1h, for the query \"attitude\" is (0,0,0,1,0,0,0,0,0,0)\n",
    "q1h = K1map[q]\n",
    "print_result(\"q1h\", q1h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8b1ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dict with 1-hot vector mapped version of each key\n",
    "K1Vdict = {\n",
    "            K1map[\"cat\"] : \"jinx\",\n",
    "       K1map[\"medicine\"] : \"meh\",\n",
    "          K1map[\"taste\"] : \"bitter\",\n",
    "       K1map[\"attitude\"] : \"yes\",\n",
    "    K1map[\"disposition\"] : \"fickle\"}\n",
    "K1Vdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322dc463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Python dict q, K, V result where q1h and K1h are 1-hot \n",
    "# mappings of both q and K are the same as KVdict[q]\n",
    "print_result(\"KVdict[q]\", KVdict[q])\n",
    "print_result(\"K1Vdict[q1h]\", K1Vdict[q1h])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0094b719",
   "metadata": {},
   "source": [
    "<img src=\"AIAYN_Draft_230426_89.png\" alt=\"Finding the value where the dot product between query and key is maximal\" />\n",
    "\n",
    "Note the only key with a nonzero dot product is the query key, q1h, so it selects the value at that maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40149b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K1h is a list of 1-hots for the key tokens\n",
    "K1h = list(K1Vdict.keys())\n",
    "# Given K1Vdict 1-hot representations of keys, select value where dot\n",
    "# product of q1h with K1h is maximal\n",
    "K1Vmaxdot = K1Vdict[\n",
    "    K1h[\n",
    "        np.argmax(np.dot(q1h, np.array(K1h).T))\n",
    "    ]\n",
    "]\n",
    "print_result(\"KVdict[q]\", KVdict[q])\n",
    "print_result(\"KVdict[argmax_i<q1h,kih_i>]\", K1Vmaxdot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bc9d06",
   "metadata": {},
   "source": [
    "<img src=\"AIAYN_Draft_230426_90.png\" alt=\"Mapping both keys and values to 1-hots\" />\n",
    "\n",
    "The only difference from the last example is that the values are mapped to their 1-hots and then the resulting 1-hot is mapped back to its token value via V1map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a048a2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dict with 1-hot vector mapped versions of keys and values\n",
    "K1V1dict = {\n",
    "            K1map[\"cat\"] : Vec1hmap[\"jinx\"],\n",
    "       K1map[\"medicine\"] : Vec1hmap[\"meh\"],\n",
    "          K1map[\"taste\"] : Vec1hmap[\"bitter\"],\n",
    "       K1map[\"attitude\"] : Vec1hmap[\"yes\"],\n",
    "    K1map[\"disposition\"] : Vec1hmap[\"fickle\"]}\n",
    "K1V1dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d2759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given K1V1dict 1-hot representations of keys & values, select\n",
    "# v1h with max dot product of q1h with K1h and show the\n",
    "# token corresponding to that v1h with Vec2token\n",
    "K1V1maxdot = V1map[\n",
    "    K1V1dict[\n",
    "        K1h[\n",
    "            np.argmax(np.dot(q1h, np.array(K1h).T))\n",
    "        ]\n",
    "    ]\n",
    "]\n",
    "print_result(\"KVdict[q]\", KVdict[q])\n",
    "print_result(\"V1map[K1V1dict[argmax_i<q1h,k1h_i>]]\", K1V1maxdot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3eda3b",
   "metadata": {},
   "source": [
    "<img src=\"AIAYN_Draft_230426_91.png\" alt=\"Weighted dot products of query vector with values vectors\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a4528b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract matrix, K (1-hots)\n",
    "K = np.array(list(K1V1dict.keys()))\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75a2cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract matrix, V (1-hots)\n",
    "V = np.array(list(K1V1dict.values()))\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca961b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given K1V1dict 1-hot representations of keys and values, \n",
    "# *weight* V by dot product of q1h with K; map 1-hot value\n",
    "# back to token value via V1map token lookup\n",
    "KVweighted = V1map[\n",
    "    tuple(\n",
    "        np.matmul(np.dot(q1h, K.T),V)\n",
    "    )\n",
    "]\n",
    "print_result(\"KVdict[q]\", KVdict[q])\n",
    "print_result(\"V1map[KVdict[sum_i<q1h,k1h_i>v1h_i]]\", KVweighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac99f5a",
   "metadata": {},
   "source": [
    "<img src=\"AIAYN_Draft_230426_92.png\" alt=\"Scaled weighted dot products of query vector with and values matrix\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91da788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizer, d_k, for no softmax and orthonormal vectors\n",
    "d_k = 1.0\n",
    "print_result(\"d_k\", d_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b613d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given K1V1dict 1-hot representations of keys and values, \n",
    "# compute 1-hot encoding of value from AIAYN matrix version \n",
    "# of self-attention via matrix multiply; map 1-hot value back\n",
    "# to token value via Vec2token\n",
    "K1V1maxdot = V1map[\n",
    "    tuple(\n",
    "        np.matmul(\n",
    "            np.matmul(q1h, K.T)/np.sqrt(d_k),\n",
    "            V)\n",
    "    )\n",
    "]\n",
    "print_result(\"KVdict[q]\", KVdict[q])\n",
    "print_result(\"V1map[((q1h)(K^T) / sqrt(d_k)) V]\", K1V1maxdot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891a1b5f",
   "metadata": {},
   "source": [
    "<img src=\"AIAYN_Draft_230426_93.png\" alt=\"Scaled dot attention with query, keys and values matrices -- full equivalence to AIAYN\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda55495",
   "metadata": {},
   "source": [
    "First, we'll do the computation without the softmax (with 1 hots), and then with it, adjusting d_k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3bf42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.array([Vec1hmap[k] for k in list(KVdict.keys())])\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adf2cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given K1V1dict 1-hot representations of keys and values, \n",
    "# compute 1-hot encoding of value from AIAYN matrix version \n",
    "# of self-attention via matrix multiply; map 1-hot value back\n",
    "# to token value via Vec2token\n",
    "Att1h = np.matmul(np.matmul(Q, K.transpose())/np.sqrt(d_k),V)\n",
    "print_result(\"Att1h\", Att1h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d10069",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For each query, the corresponding Attention_1h(Q,K,V) \\\n",
    "\\n maps to (query, value):\")\n",
    "for iv, k in enumerate(list(Q)): # for each query 1-hot in Q\n",
    "    print((Vec2token[tuple(k)], Vec2token[tuple(Att1h[iv])]))\n",
    "print(\"This was the original mapping:\")\n",
    "KVdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b3c5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return(np.exp(x)/np.exp(x).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd40d1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using the softmax to scale to 0-1, make d_k small (say 0.001)\n",
    "# and round the result\n",
    "d_ksm = 0.001\n",
    "# Compute the softmax argument with QKd\n",
    "QKd = np.matmul(Q, K.transpose())/np.sqrt(d_ksm)\n",
    "# Compute the Attention with the softmax, rounded to nearest 10th decimal\n",
    "Att = np.around(\n",
    "    np.array([np.matmul(np.array(softmax(r)),V) for r in QKd]), \n",
    "    decimals=10)\n",
    "print_result(\"Att\", Att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ed904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For each query, the corresponding Attention(Q,K,V) \\\n",
    "\\n maps to (query, value):\")\n",
    "for iv, k in enumerate(list(Q)): # for each query 1-hot in Q\n",
    "    print((Vec2token[tuple(k)], Vec2token[tuple(Att[iv])]))\n",
    "print(\"This was the original mapping:\")\n",
    "KVdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1586641a",
   "metadata": {},
   "source": [
    "<img src=\"AIAYN_Draft_230426_94.png\" alt=\"Full equivalence to AIAYN example Q.E.D.\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d0bbeb",
   "metadata": {},
   "source": [
    "<img src=\"AIAYN_Draft_230426_85.png\" alt=\"Eq (1) of Attention is All You Need\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
